# transcribe-summarize configuration
# Place in ~/.transcribe.yaml or ./.transcribe.yaml (local takes precedence)

# Whisper model: tiny, base, small, medium, large
model: base

# Minimum confidence threshold (0.0-1.0)
confidence: 0.8

# Include timestamps in transcript output
timestamps: true

# LLM provider: claude, openai, ollama
llm: claude

# For Ollama, also set OLLAMA_MODEL env var (e.g., mistral, llama3)
# llm: ollama

# Speaker names (optional, for diarization)
# speakers:
#   - Alice
#   - Bob
#   - Charlie
