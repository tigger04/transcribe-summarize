# transcribe-summarize configuration
# Place in ~/.config/transcribe-summarize/config.yaml or ./.transcribe.yaml (local takes precedence)

# Whisper model: tiny, base, small, medium, large
model: base

# Minimum confidence threshold (0.0-1.0)
confidence: 0.8

# Include timestamps in transcript output
timestamps: true

# Audio preprocessing: auto, none, analyze
preprocess: auto

# ----- LLM Configuration -----
# LLM provider: claude, openai, ollama, auto
# auto = ollama > claude > openai (local-first)
llm: auto

# For Ollama local models (no API key needed):
# ollama_model: llama3.1:8b

# For cloud providers (optional, for higher quality):
# anthropic_api_key: sk-ant-...   # Claude (overridden by ANTHROPIC_API_KEY env var)
# openai_api_key: sk-...          # OpenAI (overridden by OPENAI_API_KEY env var)

# Custom LLM priority order (default: ollama, claude, openai)
# llm_priority:
#   - ollama
#   - claude
#   - openai

# ----- Speaker Diarization -----
# Diarization works out-of-the-box using speechbrain (no setup required).
# For higher quality, set up HuggingFace token for pyannote backend.

# HuggingFace token for pyannote (overridden by HF_TOKEN env var)
# hf_token: hf_...

# Speaker names (optional - assigned in order of first appearance)
# speakers:
#   - Alice
#   - Bob
#   - Charlie
